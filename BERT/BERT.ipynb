{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e668602-586e-4b83-bfea-aace1546b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='nlptown/bert-base-multilingual-uncased-sentiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2745968e-73e2-4a07-92c1-9de6a149fdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\lib\\site-packages (4.43.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "564cabc0-ce87-4ba5-bd74-25f9fab4c0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch\n",
      "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: pytorch\n",
      "  Building wheel for pytorch (setup.py): started\n",
      "  Building wheel for pytorch (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pytorch\n",
      "Failed to build pytorch\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [6 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-install-xpjz05ir\\pytorch_729da389cfd94cd885de092f262a5d3d\\setup.py\", line 15, in <module>\n",
      "      raise Exception(message)\n",
      "  Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pytorch\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pytorch)\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36e2eead-7528-4d6d-94c1-cbd293eb7eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.69.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.0)\n",
      "Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.7 MB 429.7 kB/s eta 0:00:03\n",
      "   ------------ --------------------------- 0.5/1.7 MB 429.7 kB/s eta 0:00:03\n",
      "   ------------ --------------------------- 0.5/1.7 MB 429.7 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 0.8/1.7 MB 430.1 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 0.8/1.7 MB 430.1 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 0.8/1.7 MB 430.1 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 1.0/1.7 MB 430.0 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.0/1.7 MB 430.0 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.0/1.7 MB 430.0 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.3/1.7 MB 432.9 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.7 MB 432.9 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.7 MB 432.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.6/1.7 MB 432.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 437.6 kB/s eta 0:00:00\n",
      "Installing collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e006a-e1c7-4591-b0ad-f903b45d5575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a633d116-e7f9-483d-8710-0447430562ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-2.4216242 -2.4731674 -0.8640425  1.5004137  3.4110727]], shape=(1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*deprecated.*\")\n",
    "\n",
    "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = TFBertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Test with a sample input\n",
    "text = \"I love programming!\"\n",
    "inputs = tokenizer(text, return_tensors=\"tf\")\n",
    "output = model(**inputs)\n",
    "\n",
    "# Print output logits\n",
    "print(output.logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cd616be-3fd7-43db-9fb3-67430ba4cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def askBert(user_input):\n",
    "    inputs = tokenizer(user_input)\n",
    "    input_ids = inputs['input_ids']\n",
    "    predictions = model.predict([input_ids])\n",
    "    logits = predictions.logits\n",
    "    predicted_class = np.argmax(logits)\n",
    "    sentiment_meaning={\n",
    "        0:'very negative',\n",
    "        1:'negative',\n",
    "        2:'nutral',\n",
    "        3:'positive',\n",
    "        4:'very positive'\n",
    "    }\n",
    "    prdicted_sentiment = sentiment_meaning[predicted_class]\n",
    "    return 'The test is predicted to have a sentiment: {}'.format(prdicted_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffd30fd6-eee6-40d7-a756-fa910d24e7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The test is predicted to have a sentiment: very negative'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "askBert('i hate cars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8decf4ff-9f89-41ff-bd6d-680a34d0a05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The test is predicted to have a sentiment: positive'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "askBert('icecream is suitable for hot seasons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe962ad8-c6e0-42d0-aabb-a6fb16198b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The test is predicted to have a sentiment: very positive'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "askBert('yemen is a great countery')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3305cfd-23e0-454c-88ae-fe64cf9eefdd",
   "metadata": {},
   "source": [
    "# تحليل المشاعر في مجموعة بيانات"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "099f9fe4-0ccd-46fe-811f-83ca34855d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file = '../IMDB Dataset.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c4726ea-a838-43f2-aeda-22ae33553857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_5_rows = df.head(5)\n",
    "first_5_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fcc70f3-0d24-4559-bb76-21aff4a7deff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 324ms/step\n",
      "predicted id:  2\n",
      "['nutral']\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "predicted id:  4\n",
      "['nutral', 'very positive']\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "predicted id:  3\n",
      "['nutral', 'very positive', 'positive']\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "predicted id:  2\n",
      "['nutral', 'very positive', 'positive', 'nutral']\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "predicted id:  3\n",
      "['nutral', 'very positive', 'positive', 'nutral', 'positive']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>nutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>very positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>nutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "  predicted_sentiment  \n",
       "0              nutral  \n",
       "1       very positive  \n",
       "2            positive  \n",
       "3              nutral  \n",
       "4            positive  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sentiment_meaning={\n",
    "        0:'very negative',\n",
    "        1:'negative',\n",
    "        2:'nutral',\n",
    "        3:'positive',\n",
    "        4:'very positive'\n",
    "    }\n",
    "\n",
    "first_5_rows_copy = first_5_rows.copy()\n",
    "\n",
    "predicted_sentiments = []\n",
    "\n",
    "for title in first_5_rows_copy['review']:\n",
    "    \n",
    "    inputs = tokenizer(title,)\n",
    "    \n",
    "    input_ids = inputs['input_ids']\n",
    "    \n",
    "    predictions = model.predict([input_ids])\n",
    "    \n",
    "    logits = predictions.logits\n",
    "    \n",
    "    predicted_class = np.argmax(logits)\n",
    "    print('predicted id: ',predicted_class)\n",
    "\n",
    "    prdicted_sentiment = sentiment_meaning[predicted_class]\n",
    "\n",
    "    predicted_sentiments.append(prdicted_sentiment)\n",
    "    print(predicted_sentiments)\n",
    "\n",
    "first_5_rows_copy['predicted_sentiment'] = predicted_sentiments\n",
    "\n",
    "first_5_rows_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8f2a63e-0059-4dad-92f5-2316a75fb7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>' #علمتني_الحياه أن الذين يعيشون على الأرض ليس...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>' #ميري_كرسمس كل سنة وانتم طيبين http://t.co/n...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>' و انتهى مشوار الخواجة '</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>' مش عارف ابتدى مذاكره منين :/ '</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>' @mskhafagi  إختصروا الطريق بدلا من إختيار ال...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>' @wasfa_N الجمال مبيحتاح اي مكياج لناعم وله خ...</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>' @TheMurexDor نتمني وجود الفنانة رنا سماحة اف...</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>' ولد الهدى فالكائنات ضياء .. وفم الزمان تبسم ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>' @mohamed71944156 @samarroshdy1 انت متناقض جد...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>' منطقة السيدة زينب ليلة المولد @ مسجد السيدة ...</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2059 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet class\n",
       "0     ' #علمتني_الحياه أن الذين يعيشون على الأرض ليس...   pos\n",
       "1     ' #ميري_كرسمس كل سنة وانتم طيبين http://t.co/n...   pos\n",
       "2                             ' و انتهى مشوار الخواجة '   neg\n",
       "3                      ' مش عارف ابتدى مذاكره منين :/ '   neg\n",
       "4     ' @mskhafagi  إختصروا الطريق بدلا من إختيار ال...   neg\n",
       "...                                                 ...   ...\n",
       "2054  ' @wasfa_N الجمال مبيحتاح اي مكياج لناعم وله خ...   neu\n",
       "2055  ' @TheMurexDor نتمني وجود الفنانة رنا سماحة اف...   neu\n",
       "2056  ' ولد الهدى فالكائنات ضياء .. وفم الزمان تبسم ...   pos\n",
       "2057  ' @mohamed71944156 @samarroshdy1 انت متناقض جد...   neg\n",
       "2058  ' منطقة السيدة زينب ليلة المولد @ مسجد السيدة ...   neu\n",
       "\n",
       "[2059 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file = '../train.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66d9f922-0253-48c0-83f9-7c65029646cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>' #علمتني_الحياه أن الذين يعيشون على الأرض ليس...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>' #ميري_كرسمس كل سنة وانتم طيبين http://t.co/n...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>' و انتهى مشوار الخواجة '</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>' مش عارف ابتدى مذاكره منين :/ '</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>' @mskhafagi  إختصروا الطريق بدلا من إختيار ال...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet class\n",
       "0  ' #علمتني_الحياه أن الذين يعيشون على الأرض ليس...   pos\n",
       "1  ' #ميري_كرسمس كل سنة وانتم طيبين http://t.co/n...   pos\n",
       "2                          ' و انتهى مشوار الخواجة '   neg\n",
       "3                   ' مش عارف ابتدى مذاكره منين :/ '   neg\n",
       "4  ' @mskhafagi  إختصروا الطريق بدلا من إختيار ال...   neg"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_5_rows = df.head(5)\n",
    "first_5_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14fd8982-1332-4ade-8476-2eb264263441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 129ms/step\n",
      "predicted id:  0\n",
      "['very negative']\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "predicted id:  4\n",
      "['very negative', 'very positive']\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "predicted id:  1\n",
      "['very negative', 'very positive', 'negative']\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "predicted id:  0\n",
      "['very negative', 'very positive', 'negative', 'very negative']\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "predicted id:  0\n",
      "['very negative', 'very positive', 'negative', 'very negative', 'very negative']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>' #علمتني_الحياه أن الذين يعيشون على الأرض ليس...</td>\n",
       "      <td>pos</td>\n",
       "      <td>very negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>' #ميري_كرسمس كل سنة وانتم طيبين http://t.co/n...</td>\n",
       "      <td>pos</td>\n",
       "      <td>very positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>' و انتهى مشوار الخواجة '</td>\n",
       "      <td>neg</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>' مش عارف ابتدى مذاكره منين :/ '</td>\n",
       "      <td>neg</td>\n",
       "      <td>very negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>' @mskhafagi  إختصروا الطريق بدلا من إختيار ال...</td>\n",
       "      <td>neg</td>\n",
       "      <td>very negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet class predicted_sentiment\n",
       "0  ' #علمتني_الحياه أن الذين يعيشون على الأرض ليس...   pos       very negative\n",
       "1  ' #ميري_كرسمس كل سنة وانتم طيبين http://t.co/n...   pos       very positive\n",
       "2                          ' و انتهى مشوار الخواجة '   neg            negative\n",
       "3                   ' مش عارف ابتدى مذاكره منين :/ '   neg       very negative\n",
       "4  ' @mskhafagi  إختصروا الطريق بدلا من إختيار ال...   neg       very negative"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sentiment_meaning={\n",
    "        0:'very negative',\n",
    "        1:'negative',\n",
    "        2:'nutral',\n",
    "        3:'positive',\n",
    "        4:'very positive'\n",
    "    }\n",
    "\n",
    "first_5_rows_copy = first_5_rows.copy()\n",
    "\n",
    "predicted_sentiments = []\n",
    "\n",
    "for title in first_5_rows_copy['tweet']:\n",
    "    \n",
    "    inputs = tokenizer(title,)\n",
    "    \n",
    "    input_ids = inputs['input_ids']\n",
    "    \n",
    "    predictions = model.predict([input_ids])\n",
    "    \n",
    "    logits = predictions.logits\n",
    "    \n",
    "    predicted_class = np.argmax(logits)\n",
    "    print('predicted id: ',predicted_class)\n",
    "\n",
    "    prdicted_sentiment = sentiment_meaning[predicted_class]\n",
    "\n",
    "    predicted_sentiments.append(prdicted_sentiment)\n",
    "    print(predicted_sentiments)\n",
    "\n",
    "first_5_rows_copy['predicted_sentiment'] = predicted_sentiments\n",
    "\n",
    "first_5_rows_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77f0f82a-96f4-4ed4-b00f-807c1c972364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting camel-tools\n",
      "  Using cached camel_tools-1.5.5-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting future (from camel-tools)\n",
      "  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from camel-tools) (1.16.0)\n",
      "Collecting docopt (from camel-tools)\n",
      "  Using cached docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: cachetools in c:\\users\\user\\anaconda3\\lib\\site-packages (from camel-tools) (5.3.3)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from camel-tools) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from camel-tools) (1.13.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (from camel-tools) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (from camel-tools) (1.5.1)\n",
      "Requirement already satisfied: dill in c:\\users\\user\\anaconda3\\lib\\site-packages (from camel-tools) (0.3.8)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from camel-tools) (2.5.1)\n",
      "Collecting transformers<4.44.0,>=4.0 (from camel-tools)\n",
      "  Downloading transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting editdistance (from camel-tools)\n",
      "  Downloading editdistance-0.8.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from camel-tools) (2.32.3)\n",
      "Collecting emoji (from camel-tools)\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting pyrsistent (from camel-tools)\n",
      "  Downloading pyrsistent-0.20.0-cp312-cp312-win_amd64.whl.metadata (976 bytes)\n",
      "Requirement already satisfied: tabulate in c:\\users\\user\\anaconda3\\lib\\site-packages (from camel-tools) (0.9.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from camel-tools) (4.66.5)\n",
      "Collecting muddler (from camel-tools)\n",
      "  Downloading muddler-0.1.3-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=2.0->camel-tools) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=2.0->camel-tools) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=2.0->camel-tools) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=2.0->camel-tools) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=2.0->camel-tools) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=2.0->camel-tools) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=2.0->camel-tools) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->camel-tools) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers<4.44.0,>=4.0->camel-tools) (0.27.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers<4.44.0,>=4.0->camel-tools) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers<4.44.0,>=4.0->camel-tools) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers<4.44.0,>=4.0->camel-tools) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers<4.44.0,>=4.0->camel-tools) (0.5.2)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers<4.44.0,>=4.0->camel-tools)\n",
      "  Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm->camel-tools) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->camel-tools) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->camel-tools) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->camel-tools) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->camel-tools) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->camel-tools) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->camel-tools) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->camel-tools) (2024.8.30)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn->camel-tools) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn->camel-tools) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0->camel-tools) (2.1.3)\n",
      "Downloading camel_tools-1.5.5-py3-none-any.whl (124 kB)\n",
      "Downloading transformers-4.43.4-py3-none-any.whl (9.4 MB)\n",
      "   ---------------------------------------- 0.0/9.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/9.4 MB 429.7 kB/s eta 0:00:21\n",
      "   -- ------------------------------------- 0.5/9.4 MB 429.7 kB/s eta 0:00:21\n",
      "   -- ------------------------------------- 0.5/9.4 MB 429.7 kB/s eta 0:00:21\n",
      "   --- ------------------------------------ 0.8/9.4 MB 435.8 kB/s eta 0:00:20\n",
      "   --- ------------------------------------ 0.8/9.4 MB 435.8 kB/s eta 0:00:20\n",
      "   --- ------------------------------------ 0.8/9.4 MB 435.8 kB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 1.0/9.4 MB 433.8 kB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 1.0/9.4 MB 433.8 kB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 1.3/9.4 MB 432.9 kB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 1.3/9.4 MB 432.9 kB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 1.3/9.4 MB 432.9 kB/s eta 0:00:19\n",
      "   ------ --------------------------------- 1.6/9.4 MB 434.6 kB/s eta 0:00:19\n",
      "   ------ --------------------------------- 1.6/9.4 MB 434.6 kB/s eta 0:00:19\n",
      "   ------ --------------------------------- 1.6/9.4 MB 434.6 kB/s eta 0:00:19\n",
      "   ------- -------------------------------- 1.8/9.4 MB 433.9 kB/s eta 0:00:18\n",
      "   ------- -------------------------------- 1.8/9.4 MB 433.9 kB/s eta 0:00:18\n",
      "   ------- -------------------------------- 1.8/9.4 MB 433.9 kB/s eta 0:00:18\n",
      "   -------- ------------------------------- 2.1/9.4 MB 433.3 kB/s eta 0:00:17\n",
      "   -------- ------------------------------- 2.1/9.4 MB 433.3 kB/s eta 0:00:17\n",
      "   -------- ------------------------------- 2.1/9.4 MB 433.3 kB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 2.4/9.4 MB 434.4 kB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 2.4/9.4 MB 434.4 kB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 2.6/9.4 MB 433.9 kB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 2.6/9.4 MB 433.9 kB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 2.6/9.4 MB 433.9 kB/s eta 0:00:16\n",
      "   ------------ --------------------------- 2.9/9.4 MB 433.5 kB/s eta 0:00:16\n",
      "   ------------ --------------------------- 2.9/9.4 MB 433.5 kB/s eta 0:00:16\n",
      "   ------------ --------------------------- 2.9/9.4 MB 433.5 kB/s eta 0:00:16\n",
      "   ------------- -------------------------- 3.1/9.4 MB 434.2 kB/s eta 0:00:15\n",
      "   ------------- -------------------------- 3.1/9.4 MB 434.2 kB/s eta 0:00:15\n",
      "   ------------- -------------------------- 3.1/9.4 MB 434.2 kB/s eta 0:00:15\n",
      "   -------------- ------------------------- 3.4/9.4 MB 433.9 kB/s eta 0:00:14\n",
      "   -------------- ------------------------- 3.4/9.4 MB 433.9 kB/s eta 0:00:14\n",
      "   -------------- ------------------------- 3.4/9.4 MB 433.9 kB/s eta 0:00:14\n",
      "   --------------- ------------------------ 3.7/9.4 MB 433.6 kB/s eta 0:00:14\n",
      "   --------------- ------------------------ 3.7/9.4 MB 433.6 kB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 3.9/9.4 MB 434.2 kB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 3.9/9.4 MB 434.2 kB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 3.9/9.4 MB 434.2 kB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 4.2/9.4 MB 433.9 kB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 4.2/9.4 MB 433.9 kB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 4.2/9.4 MB 433.9 kB/s eta 0:00:13\n",
      "   ------------------ --------------------- 4.5/9.4 MB 432.3 kB/s eta 0:00:12\n",
      "   ------------------ --------------------- 4.5/9.4 MB 432.3 kB/s eta 0:00:12\n",
      "   ------------------ --------------------- 4.5/9.4 MB 432.3 kB/s eta 0:00:12\n",
      "   -------------------- ------------------- 4.7/9.4 MB 432.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 4.7/9.4 MB 432.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 4.7/9.4 MB 432.8 kB/s eta 0:00:11\n",
      "   --------------------- ------------------ 5.0/9.4 MB 432.6 kB/s eta 0:00:11\n",
      "   --------------------- ------------------ 5.0/9.4 MB 432.6 kB/s eta 0:00:11\n",
      "   --------------------- ------------------ 5.0/9.4 MB 432.6 kB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 5.2/9.4 MB 432.5 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 5.2/9.4 MB 432.5 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 5.2/9.4 MB 432.5 kB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 5.5/9.4 MB 432.9 kB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 5.5/9.4 MB 432.9 kB/s eta 0:00:10\n",
      "   ------------------------ --------------- 5.8/9.4 MB 432.8 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 5.8/9.4 MB 432.8 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 5.8/9.4 MB 432.8 kB/s eta 0:00:09\n",
      "   ------------------------- -------------- 6.0/9.4 MB 432.7 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 6.0/9.4 MB 432.7 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 6.0/9.4 MB 432.7 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 6.3/9.4 MB 433.1 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 6.3/9.4 MB 433.1 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 6.3/9.4 MB 433.1 kB/s eta 0:00:08\n",
      "   --------------------------- ------------ 6.6/9.4 MB 432.9 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 6.6/9.4 MB 432.9 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 6.6/9.4 MB 432.9 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 6.8/9.4 MB 433.3 kB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 6.8/9.4 MB 433.3 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 7.1/9.4 MB 433.2 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 7.1/9.4 MB 433.2 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 7.1/9.4 MB 433.2 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 7.3/9.4 MB 433.1 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 7.3/9.4 MB 433.1 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 7.3/9.4 MB 433.1 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 7.6/9.4 MB 434.1 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 7.6/9.4 MB 434.1 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 7.6/9.4 MB 434.1 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 7.9/9.4 MB 434.0 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 7.9/9.4 MB 434.0 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 8.1/9.4 MB 433.9 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 8.1/9.4 MB 433.9 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 8.1/9.4 MB 433.9 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 8.4/9.4 MB 433.8 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 8.4/9.4 MB 433.8 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 8.4/9.4 MB 433.8 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 8.7/9.4 MB 434.0 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 8.7/9.4 MB 434.0 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 8.7/9.4 MB 434.0 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 8.9/9.4 MB 433.9 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 8.9/9.4 MB 433.9 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 8.9/9.4 MB 433.9 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 9.2/9.4 MB 433.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.2/9.4 MB 433.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.2/9.4 MB 433.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.4/9.4 MB 433.5 kB/s eta 0:00:00\n",
      "Downloading editdistance-0.8.1-cp312-cp312-win_amd64.whl (79 kB)\n",
      "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "   ---------------------------------------- 0.0/590.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/590.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/590.6 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 262.1/590.6 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 262.1/590.6 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 262.1/590.6 kB ? eta -:--:--\n",
      "   --------------------------------- ---- 524.3/590.6 kB 430.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- 590.6/590.6 kB 447.5 kB/s eta 0:00:00\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Downloading muddler-0.1.3-py3-none-any.whl (16 kB)\n",
      "Downloading pyrsistent-0.20.0-cp312-cp312-win_amd64.whl (63 kB)\n",
      "Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 399.6 kB/s eta 0:00:05\n",
      "   --------- ------------------------------ 0.5/2.2 MB 399.6 kB/s eta 0:00:05\n",
      "   --------- ------------------------------ 0.5/2.2 MB 399.6 kB/s eta 0:00:05\n",
      "   -------------- ------------------------- 0.8/2.2 MB 414.1 kB/s eta 0:00:04\n",
      "   -------------- ------------------------- 0.8/2.2 MB 414.1 kB/s eta 0:00:04\n",
      "   -------------- ------------------------- 0.8/2.2 MB 414.1 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 1.0/2.2 MB 419.4 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 1.0/2.2 MB 419.4 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 1.0/2.2 MB 419.4 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 422.1 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 422.1 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 422.1 kB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 423.6 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 423.6 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 1.8/2.2 MB 430.2 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 430.2 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 430.2 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.1/2.2 MB 430.1 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.1/2.2 MB 430.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 429.4 kB/s eta 0:00:00\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13775 sha256=ae6052546f6060e18c1bea56c344bfc6c4889db47c3d4b61ea37858bfa88e65a\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\1a\\bf\\a1\\4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
      "Successfully built docopt\n",
      "Installing collected packages: docopt, pyrsistent, muddler, future, emoji, editdistance, tokenizers, transformers, camel-tools\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.0\n",
      "    Uninstalling tokenizers-0.21.0:\n",
      "      Successfully uninstalled tokenizers-0.21.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.48.0\n",
      "    Uninstalling transformers-4.48.0:\n",
      "      Successfully uninstalled transformers-4.48.0\n",
      "Successfully installed camel-tools-1.5.5 docopt-0.6.2 editdistance-0.8.1 emoji-2.14.1 future-1.0.0 muddler-0.1.3 pyrsistent-0.20.0 tokenizers-0.19.1 transformers-4.43.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\anaconda3\\Lib\\site-packages\\~okenizers'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "pip install camel-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e79e3fbf-8680-4316-bb58-5a6437d7f709",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.bert.modeling_bert because of the following error (look up to see its traceback):\ncannot import name 'is_torch_greater_or_equal_than_1_13' from 'transformers.pytorch_utils' (C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\pytorch_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1817\u001b[0m, in \u001b[0;36m_get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:46\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     36\u001b[0m     BaseModelOutputWithPastAndCrossAttentions,\n\u001b[0;32m     37\u001b[0m     BaseModelOutputWithPoolingAndCrossAttentions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m     TokenClassifierOutput,\n\u001b[0;32m     45\u001b[0m )\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:48\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftAdapterMixin, deepspeed_config, is_deepspeed_zero3_enabled\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     Conv1D,\n\u001b[0;32m     50\u001b[0m     apply_chunking_to_forward,\n\u001b[0;32m     51\u001b[0m     find_pruneable_heads_and_indices,\n\u001b[0;32m     52\u001b[0m     id_tensor_storage,\n\u001b[0;32m     53\u001b[0m     is_torch_greater_or_equal_than_1_13,\n\u001b[0;32m     54\u001b[0m     prune_conv1d_layer,\n\u001b[0;32m     55\u001b[0m     prune_layer,\n\u001b[0;32m     56\u001b[0m     prune_linear_layer,\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoHfQuantizer, HfQuantizer\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'is_torch_greater_or_equal_than_1_13' from 'transformers.pytorch_utils' (C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\pytorch_utils.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, TFBertForSequenceClassification\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcamel_tools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msentiment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentimentAnalyzer\n\u001b[0;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m SentimentAnalyzer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAMeL-Lab/bert-base-arabic-camelbert-mix-sentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mانا اكره علمي\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\camel_tools\\sentiment\\__init__.py:33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtorch_fun\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertForSequenceClassification\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcamel_tools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CATALOGUE\n\u001b[0;32m     38\u001b[0m _LABELS \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1806\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1804\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1805\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m-> 1806\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1807\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[0;32m   1808\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1805\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1819\u001b[0m, in \u001b[0;36m_get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.models.bert.modeling_bert because of the following error (look up to see its traceback):\ncannot import name 'is_torch_greater_or_equal_than_1_13' from 'transformers.pytorch_utils' (C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\pytorch_utils.py)"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from camel_tools.sentiment import SentimentAnalyzer\n",
    "model_name = SentimentAnalyzer(\"CAMeL-Lab/bert-base-arabic-camelbert-mix-sentiment\")\n",
    "sentences = ['انا اكره علمي']\n",
    "model_name.predict(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6cb24d-478e-4be1-8cba-47e4f6e0edb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
